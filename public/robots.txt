# Ruzma robots.txt - Updated for SEO & GEO (Generative Engine Optimization)
# Last updated: 2025-10-20

# Default rule - allow all
User-agent: *
Allow: /

# Traditional Search Engine Crawlers
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Yandex
Allow: /

User-agent: DuckDuckBot
Allow: /

# Social Media Crawlers
User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /

User-agent: LinkedInBot
Allow: /

# AI-Powered Search Engine Crawlers (Critical for GEO)
# These crawlers help AI search engines index and cite your content

User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: Applebot-Extended
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: Omgilibot
Allow: /

User-agent: FacebookBot
Allow: /

# Block paths that shouldn't be indexed
Disallow: /api/
Disallow: /admin/
Disallow: /_next/
Disallow: /private/

# Sitemap location (will be created in next step)
Sitemap: https://app.ruzma.co/sitemap.xml

# Crawl delay (optional, for rate limiting)
# Crawl-delay: 1

# Additional directives for better crawling
# Allow both language versions
Allow: /en/
Allow: /ar/
